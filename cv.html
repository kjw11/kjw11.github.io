<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Jiawen Kang</title>
    <link rel="stylesheet" href="main.css">
</head>

<body>
<div id="container">

    <ul id="nav">
        <li><a href="index.html"> <em>home</em> </a> </li>
        <li><a href="papers.html"> <em>papers</em></a></li>
        <li><a href="cv.html"><u><em>cv</em></u></a></li>
    </ul>

    <div class="clear"></div>

    <div class="cv">
        <h3>education</h3>
        <ul>
            <p id="p_l">2021 - Now</p>
            <p id="p_r">Ph.D. in Information System, The Chinese University of Hong Kong</p>
        </ul><ul>
            <p id="p_l">2019 - 2021</p>
            <p id="p_r">B.Eng. in Electrical Engineering, Jilin University
        </ul>

        <div class="clear"></div>
        <h3>experience</h3>
        <ul>
            <p id="p_l">Nov. 2020 - Jul. 2021</p> 
            <p id="p_r">Research Assistant, The Chinese University of Hong Kong</p>
        </ul><ul>
            <p id="p_l">Sep. 2019 - Oct. 2020</p>
            <p id="p_r">Research Assistant, Centor for Speech and Language Technology, Tsinghua University</p>
        </ul><ul>
            <p id="p_l">Nov. 2017 - Nov. 2018</p>
            <p id="p_r">Undergraduate Research Intern, CIEE, Jilin University</p>
        </ul>

        <div class="clear"></div>
        <h3>challenges</h3>
        <ul>
            <p id="p_l">2th/14 place</p>
            <p id="p_r"> <a href="https://www.alibabacloud.com/m2met-alimeeting">2022 ICASSP M2MeT challenge Track 1</a></p>
        </ul>

        <div class="clear"></div>
        <h3>open source</h3>
        <ul>
            <p id="p_l">Paper code</p>
            <p id="p_r"> Cross-speaker encoding network for multi-talker speech recognition (<a href="https://github.com/kjw11/CSEnet-ASR">GitHub link</a>) </p>
        </ul><ul>
            <p id="p_l">Paper code</p>
            <p id="p_r"> Domain-invariant speaker vector projection by model-agnostic meta-learnin (<a href="https://github.com/kjw11/MAML-Speaker">GitHub link</a>) </p>
        </ul><ul>
            <p id="p_l">Dataset</p>
            <p id="p_r"> Cn-celeb: a multi-genre speaker recognition dataset (<a href="https://openslr.org/82/">OpenSLR link</a>) </p>
        </ul><ul>
            <p id="p_l">Code</p>
            <p id="p_r"> Speaker recognition Kaldi recipe (<a href="https://github.com/kaldi-asr/kaldi/tree/master/egs/cnceleb">Kaldi GitHub link</a>) </p>
        </ul>

        <div class="clear"></div>
        <h3>awards</h3>
        <ul>
            <p id="p_l">2024</p>
            <p id="p_r"> ISCA Award for the Best Paper Published in Speech Communication (2019-2023)</p>
        </ul><ul>
            <p id="p_l">2022</p>
            <p id="p_r"> Most Cited Article of Speech Communication </p>
        </ul><ul>
            <p id="p_l">2021</p>
            <p id="p_r"> Postgraduate Studentship, The Chinese University of Hong Kong </p>
        </ul><ul>
            <p id="p_l">2018</p>
            <p id="p_r"> National-level project, the national undergraduate students innovation and entrepreneurship training program </p>
        </ul>

        <div class="clear"></div>
        <h3>teaching</h3>
        <ul>
            <p id="p_l">Teaching Assistant</p>
            <p id="p_r">SEEM2460 Introduction to Data Science (Spring 2024/2023/2022)</p>
            </p>
        </ul><ul>
            <p id="p_l">Teaching Assistant</p>
            <p id="p_r">ENGG2780 Statistics for Engineers (Spring 2023/2022)</p>
        </ul>

        <div class="clear"></div>
        <h3></h3>
        My full CV can be downloaded <a href="assets/JwKang_cv.pdf">here</a>.

    </div>

</div>

<br><br><br><br>
</body>
</html>